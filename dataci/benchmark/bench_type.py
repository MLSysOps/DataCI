#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Author: Li Yuanming
Email: yuanmingleee@gmail.com
Date: Mar 23, 2023
"""
from typing import TYPE_CHECKING

import pandas as pd

if TYPE_CHECKING:
    from dataci.dataset.dataset import Dataset


def same_train_val_checker(train_dataset: 'Dataset', test_dataset: 'Dataset'):
    """Check if the provided train and val dataset are two splits of a common parent dataset.
    """
    # 1.the train and test dataset should have a parent dataset
    train_parent_dataset = train_dataset.parent_dataset or train_dataset
    val_parent_dataset = test_dataset.parent_dataset or test_dataset
    # TODO: a better split checking design
    if train_parent_dataset.name.split('_')[0] != val_parent_dataset.name.split('_')[0]:
        return False
    return True


def standalone_checker(dataset: 'Dataset'):
    """Check if the provided dataset is a standalone dataset (i.e., not generated by any pipeline).
    """
    # 1. If the dataset is a standalone dataset, the dataset should not have a parent dataset
    if dataset.parent_dataset is not None:
        return False
    return True


def text_augmentation_checker(dataset: 'Dataset'):
    """Check if the provided dataset are generated by text augmentation.
    """
    # Dataset and it's parent dataset (if any) is augmented without removing any of the data.
    # Therefore, all data ID in the input dataset will be in the output dataset.

    # 1. If the dataset is generated by text augmentation, the dataset should have a parent dataset
    if dataset.parent_dataset is None:
        return False
    # 2. If the dataset is generated by text augmentation, the dataset should have all
    #   `id_column` in the parent dataset
    dataset_df: 'pd.DataFrame' = pd.read_csv(dataset.dataset_files)
    parent_dataset_df: 'pd.DataFrame' = pd.read_csv(dataset.parent_dataset.dataset_files)
    dataset_id_set = set(dataset_df[dataset.id_column])
    parent_dataset_id_set = set(parent_dataset_df[dataset.parent_dataset.id_column])
    if dataset_id_set != parent_dataset_id_set:
        return False
    return True


def text_selection_checker(dataset: 'Dataset'):
    """Check if the provided dataset is generated by text selection.
    """
    # Part of the pipeline input data are output, without any modification on these
    # data records (i.e., all fields for those selected data are identical to its
    # parent dataset.

    # 1. If the dataset is generated by text augmentation, the dataset should have a parent dataset
    if dataset.parent_dataset is None:
        return False
    # 2. If the dataset is generated by text augmentation, the dataset should have a subset of
    #   `id_column` in the parent dataset
    dataset_df: 'pd.DataFrame' = pd.read_csv(dataset.dataset_files)
    parent_dataset_df: 'pd.DataFrame' = pd.read_csv(dataset.parent_dataset.dataset_files)
    dataset_id_set = set(dataset_df[dataset.id_column])
    parent_dataset_id_set = set(parent_dataset_df[dataset.parent_dataset.id_column])
    if not dataset_id_set.issubset(parent_dataset_id_set):
        return False
    # 3. If the dataset is generated by text augmentation, the dataset should have identical
    #   fields for those selected data
    if (parent_dataset_df.iloc[dataset_id_set] != dataset_df).all():
        return False
    return True


def verify_bench_type(bench_type: str, train_dataset: 'Dataset', test_dataset: 'Dataset'):
    """Check if provided benchmark type is available for train and val dataset.
    """
    print(train_dataset.dataset_files)
    if bench_type == 'data_augmentation':
        return text_augmentation_checker(train_dataset) and (
                text_augmentation_checker(test_dataset) or standalone_checker(test_dataset)
        ) and same_train_val_checker(train_dataset, test_dataset)
    elif bench_type == 'data_selection':
        return text_selection_checker(train_dataset) and (
                text_selection_checker(test_dataset) or standalone_checker(test_dataset)
        ) and same_train_val_checker(train_dataset, test_dataset)
    raise ValueError(f'Unsupported benchmark type: {bench_type}')

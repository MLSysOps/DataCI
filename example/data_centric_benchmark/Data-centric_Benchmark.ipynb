{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "In the previous tutorial, we showed how DataCI helps manage and build datasets with different raw datasets and\n",
    "pipelines. In this tutorial, we will show how to use DataCI to benchmark the dataset.\n",
    "\n",
    "Data is the most important part of the machine learning pipeline. Data scientists spend most of their time cleaning,\n",
    "augmenting, and preprocessing data, only to find the best online performance with the same model structure.\n",
    "[In the previous tutorial](/example/create_text_classification_dataset), we built 4 versions of the text classification\n",
    "dataset `train_data_pipeline:text_aug`. We are now going to determine which dataset performs the best."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 0. Prerequisites"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%pip install scikit-learn\n",
    "%pip install transformers\n",
    "print(\n",
    "    'You should also install pytorch, check https://pytorch.org/get-started/locally/ to find specific version '\n",
    "    'matches your OS, package and platform'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "% cd../../\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ['PYTHONPATH'] = os.getcwd()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We are using datasets built in the previous tutorial, please make sure you have run the previous tutorial."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Publish text classification dataset v1 - v4\n",
    "\n",
    "We have published 4 versions of the text classification dataset in the previous tutorial.\n",
    "We can list them with the following command:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!python dataci/command/dataset.py ls train_data_pipeline:text_aug"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Benchmark Text Classification Dataset\n",
    "\n",
    "Recall that in the previous tutorial, we have benchmark the performance of the text classification dataset v1 by\n",
    "a training script. We can do so easily with DataCI's data-centric benchmark tool.\n",
    "\n",
    "## 1.1 Benchmark text classification dataset v1\n",
    "\n",
    "Get text classification dataset v1 as train dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from dataci.dataset import list_dataset\n",
    "\n",
    "# Get all versions of the text classification dataset\n",
    "text_classification_datasets = list_dataset('train_data_pipeline:text_aug', tree_view=False)\n",
    "# Sort by created date\n",
    "text_classification_datasets.sort(key=lambda x: x.create_date)\n",
    "train_dataset = text_classification_datasets[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Get validation split of the raw text dataset v1 as test dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get all versions of the raw text dataset val split\n",
    "text_raw_val_datasets = list_dataset('text_raw_val', tree_view=False)\n",
    "# Sort by created date\n",
    "text_raw_val_datasets.sort(key=lambda x: x.create_date)\n",
    "test_dataset = text_raw_val_datasets[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since the text classification dataset v1 are built with the data augmentation pipeline `train_data_pipeline`,\n",
    "we will perform `data_augmentation` data-centric benchmark, with `text_classification` ML task.\n",
    "\n",
    "We will use `bert-base-cased` as the model name, and only train for 3 epochs with 10 steps per epoch for demo purpose."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from dataci.benchmark import Benchmark\n",
    "\n",
    "\n",
    "benchmark = Benchmark(\n",
    "    type='data_augmentation',\n",
    "    ml_task='text_classification',\n",
    "    model_name='bert-base-cased',\n",
    "    train_dataset=train_dataset,\n",
    "    test_dataset=test_dataset,\n",
    "    train_kwargs=dict(\n",
    "        epochs=3,\n",
    "        batch_size=4,\n",
    "        learning_rate=1e-5,\n",
    "        logging_steps=1,\n",
    "        max_train_steps_per_epoch=10,\n",
    "        max_val_steps_per_epoch=10,\n",
    "        seed=42,\n",
    "    ),\n",
    ")\n",
    "# Run benchmark\n",
    "benchmark.run()\n",
    "\n",
    "# Check benchmark results\n",
    "print(benchmark.metrics)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.2 Benchmark all text classification datasets (v2 - v4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for text_classification_dataset in text_classification_datasets[1:]:\n",
    "    benchmark = Benchmark(\n",
    "        type='data_augmentation',\n",
    "        ml_task='text_classification',\n",
    "        model_name='bert-base-cased',\n",
    "        train_dataset=text_classification_dataset,\n",
    "        test_dataset=test_dataset,\n",
    "        train_kwargs=dict(\n",
    "            epochs=3,\n",
    "            batch_size=4,\n",
    "            learning_rate=1e-5,\n",
    "            logging_steps=1,\n",
    "            max_train_steps_per_epoch=10,\n",
    "            max_val_steps_per_epoch=10,\n",
    "            seed=42,\n",
    "        ),\n",
    "    )\n",
    "    # Run benchmark\n",
    "    benchmark.run()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Summary\n",
    "\n",
    "## 2.1 What is the best dataset for text classification?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!python dataci/command/benchmark.py ls -me=val/loss,val/acc,test/acc,test/batch_time train_data_pipeline:text_aug"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.2 What is the best data augmentation pipeline for text classification?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!python dataci/command/benchmark.py lsp -me=val/loss,val/acc,test/acc,test/batch_time train_data_pipeline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}